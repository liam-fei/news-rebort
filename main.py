# =============================================
# Fredly News Bot - Smart Discovery Edition
# æ™ºèƒ½æŽ¢æµ‹æ¨¡åž‹ (ä¼˜å…ˆ 2.0/2.5 -> åŽå¤‡ 1.5)
# =============================================

import os
import sys
import asyncio
import schedule
import time
import feedparser
import edge_tts
import requests
import json
from datetime import datetime
from pathlib import Path
from telegram.ext import Application
from telegram.request import HTTPXRequest

# ---------------- CONFIG ----------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

if not all([GEMINI_API_KEY, TELEGRAM_BOT_TOKEN, CHAT_ID]):
    print("Error: Missing Environment Variables")
    sys.exit(1)

# ä½¿ç”¨ v1beta æŽ¥å£ä»¥èŽ·å–æœ€æ–°çš„å®žéªŒæ¨¡åž‹åˆ—è¡¨
BASE_URL = "https://generativelanguage.googleapis.com/v1beta"

VOICE_NAME = "en-US-AvaNeural"
TARGET_MINUTES = 15
ARTICLES_LIMIT = 3

RSS_FEEDS = {
    "Global News": ["http://feeds.bbci.co.uk/news/rss.xml", "http://rss.cnn.com/rss/edition.rss"],
    "Business": ["https://feeds.bloomberg.com/markets/news.rss"],
    "Tech": ["https://techcrunch.com/feed/"],
    "Sports": ["https://www.espn.com/espn/rss/news"]
}

OUTPUT_DIR = Path("./outputs")
OUTPUT_DIR.mkdir(exist_ok=True)

# ---------------- SMART MODEL FINDER ----------------

def get_working_api_url():
    """
    è‡ªåŠ¨å‘ Google è¯¢é—®å¯ç”¨æ¨¡åž‹ï¼Œå¹¶è¿”å›žå¯ç”¨çš„ç”Ÿæˆ URLã€‚
    """
    print("ðŸ” Auto-detecting available models...")
    try:
        # 1. èŽ·å–æ¨¡åž‹åˆ—è¡¨
        list_url = f"{BASE_URL}/models?key={GEMINI_API_KEY}"
        resp = requests.get(list_url, timeout=10)
        
        if resp.status_code != 200:
            print(f"âŒ Failed to get models list: {resp.text}")
            return None

        data = resp.json()
        if 'models' not in data:
            print(f"âŒ API Key valid but no models found. (Check Google AI Studio)")
            return None

        # 2. ç­›é€‰å‡ºæ”¯æŒæ–‡æœ¬ç”Ÿæˆçš„æ¨¡åž‹
        candidates = []
        print("ðŸ“‹ Available Models for your Key:")
        for m in data['models']:
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                model_name = m['name']
                candidates.append(model_name)
                # æ‰“å°å‡ºæ¥æ–¹ä¾¿è°ƒè¯•
                print(f"   -> {model_name}")

        if not candidates:
            print("âŒ No text generation models available.")
            return None

        # 3. æ™ºèƒ½é€‰æ‹©ï¼šä¼˜å…ˆ 2.x Flash/Pro -> 1.5 Flash -> å…¶ä»–
        # æ³¨æ„ï¼šGoogle è¿”å›žçš„ name é€šå¸¸åŒ…å« 'models/' å‰ç¼€
        priority_patterns = [
            'gemini-2.5',       # æœªæ¥ç‰ˆæœ¬
            'gemini-2.0-flash', # æžé€Ÿç‰ˆ
            'gemini-2.0-pro',   # å¼ºåŠ›ç‰ˆ
            'gemini-1.5-flash', # æœ€ç¨³åŽå¤‡
            'gemini-1.5-pro',   # å¼ºåŠ›åŽå¤‡
        ]
        
        chosen_model = None
        for pattern in priority_patterns:
            # åœ¨å€™é€‰åˆ—è¡¨ä¸­å¯»æ‰¾åŒ…å«è¯¥ pattern çš„æ¨¡åž‹
            match = next((m for m in candidates if pattern in m), None)
            if match:
                chosen_model = match
                print(f"âš¡ Match found for priority '{pattern}': {chosen_model}")
                break
        
        if not chosen_model:
            chosen_model = candidates[0]  # å…œåº•ç”¨ç¬¬ä¸€ä¸ª
            print(f"âš ï¸ No priority match, using fallback: {chosen_model}")
        
        print(f"âœ… Selected working model: {chosen_model}")
        
        # 4. æž„é€ æœ€ç»ˆ URL
        # chosen_model å·²ç»åŒ…å« 'models/' å‰ç¼€ï¼Œç›´æŽ¥æ‹¼æŽ¥
        generate_url = f"{BASE_URL}/{chosen_model}:generateContent?key={GEMINI_API_KEY}"
        return generate_url

    except Exception as e:
        print(f"âŒ Discovery failed: {e}")
        return None

# ---------------- CORE LOGIC ----------------

def fetch_rss_news():
    print("\n>>> Fetching RSS Feeds...")
    articles = []
    for category, feeds in RSS_FEEDS.items():
        count = 0
        for url in feeds:
            if count >= ARTICLES_LIMIT: break
            try:
                d = feedparser.parse(url)
                for entry in d.entries[:ARTICLES_LIMIT]:
                    articles.append({
                        "category": category,
                        "title": entry.get("title", ""),
                        "summary": entry.get("summary", "")[:1000]
                    })
                    count += 1
            except Exception as e:
                print(f"Skip feed {url}: {e}")
    print(f"âœ… Fetched {len(articles)} articles")
    return articles

def generate_script_via_http(articles):
    # åŠ¨æ€èŽ·å– URL
    api_url = get_working_api_url()
    if not api_url:
        print("âŒ Could not find a valid model URL. Aborting.")
        return None

    print(f"ðŸ¤– Generating Script...")
    
    prompt_text = (
        f"You are Sara, a warm news anchor. Create a {TARGET_MINUTES}-minute news script. "
        f"Professional, spoken style. Plain text only. Articles: \n"
    )
    for art in articles:
        prompt_text += f"[{art['category']}] {art['title']}: {art['summary']}\n---\n"

    payload = {
        "contents": [{
            "parts": [{"text": prompt_text}]
        }]
    }

    try:
        response = requests.post(
            api_url, 
            headers={'Content-Type': 'application/json'},
            data=json.dumps(payload),
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            try:
                if 'candidates' in result and result['candidates']:
                    script = result['candidates'][0]['content']['parts'][0]['text']
                    print("âœ… Script Generated Successfully")
                    return script
                else:
                    print(f"âŒ Empty Response (Safety/Quota?): {result}")
                    return None
            except (KeyError, IndexError):
                print(f"âŒ Json Parse Error: {result}")
                return None
        else:
            print(f"âŒ API Error: {response.status_code} - {response.text}")
            return None

    except Exception as e:
        print(f"âŒ Connection Error: {e}")
        return None

async def tts_and_upload(script_text):
    date_str = datetime.now().strftime("%Y-%m-%d")
    mp3_path = OUTPUT_DIR / f"news_{date_str}.mp3"

    print("ðŸŽ™ï¸ Synthesizing Audio (Edge TTS)...")
    try:
        await edge_tts.Communicate(script_text, VOICE_NAME).save(mp3_path)
    except Exception as e:
        print(f"âŒ TTS Failed: {e}"); return

    print("ðŸ“¤ Uploading to Telegram...")
    try:
        t_request = HTTPXRequest(read_timeout=300.0, write_timeout=300.0)
        app = Application.builder().token(TELEGRAM_BOT_TOKEN).request(t_request).build()
        async with app:
            await app.initialize()
            with open(mp3_path, "rb") as f:
                await app.bot.send_audio(chat_id=CHAT_ID, audio=f, caption=f"ðŸŽ™ï¸ News Briefing {date_str}")
        print("âœ… Message Sent!")
        if mp3_path.exists():
            os.remove(mp3_path)
    except Exception as e:
        print(f"âŒ Telegram Failed: {e}")

# ---------------- SCHEDULER ----------------

def run_daily_job():
    print(f"\n>>> Job Started: {datetime.now()}")
    news = fetch_rss_news()
    if not news: return
    script = generate_script_via_http(news)
    if not script: return
    asyncio.run(tts_and_upload(script))
    print("<<< Job Finished\n")

if __name__ == "__main__":
    from keep_alive import keep_alive
    keep_alive()

    print(f"ðŸš€ Fredly News Bot (Smart Discovery) Ready")
    schedule.every().day.at("03:00").do(run_daily_job)

    if os.getenv("RUN_NOW", "false").lower() == "true":
        run_daily_job()

    while True:
        schedule.run_pending()
        time.sleep(60)
