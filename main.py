# =============================================
# Fredly News Bot - Global & China Focus (24H Strict)
# ç‰¹æ€§ï¼šå¼ºåˆ¶åŒ…å«ä¸­å›½çƒ­ç‚¹ + ä¸¥æ ¼24å°æ—¶è¿‡æ»¤ + å»ç¾å›½åŒ–
# æ¨¡å¼ï¼šéªŒè¯æ¨¡å¼ (åªè¾“å‡ºæ–‡æœ¬æ—¥å¿—ï¼Œä¸å‘TG/éŸ³é¢‘)
# =============================================

import os
import sys
import time
import json
import tarfile
import asyncio
import shutil
import re
import subprocess
import logging
import random
from datetime import datetime, timedelta
from time import mktime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
import feedparser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ---------------- LOGGING ----------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S"
)
log = logging.getLogger("Fredly_Verify")

# ---------------- CONFIG ----------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
# éªŒè¯æ¨¡å¼ä¸‹å¯ä¸ºç©º
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN") 
CHAT_ID = os.getenv("CHAT_ID")

if not GEMINI_API_KEY:
    log.error("âŒ Missing GEMINI_API_KEY")
    sys.exit(1)

BASE_URL = "https://generativelanguage.googleapis.com/v1beta"
TARGET_MINUTES = 13

# ---------------- RSS SOURCES (Global + China) ----------------
# ä½¿ç”¨ gl=GB (è‹±å›½ç‰ˆ) å’Œ gl=SG (æ–°åŠ å¡ç‰ˆ) æ¥è·å–æ›´å›½é™…åŒ–å’Œäºšæ´²è§†è§’çš„æŠ¥é“
RSS_POOLS = {
    # 1. å…¨çƒå¤´æ¡ (è‹±å›½ç‰ˆ - åå‘BBC/è·¯é€)
    "WORLD_TOP": "https://news.google.com/rss?hl=en-GB&gl=GB&ceid=GB:en",
    
    # 2. ä¸­å›½ä¸“é¢˜ (å¼ºåˆ¶æœç´¢ 'China' ä¸”é™å®š when:1d è¿‡å»24å°æ—¶)
    "CHINA_HOT": "https://news.google.com/rss/search?q=China+when:1d&hl=en-GB&gl=GB&ceid=GB:en",
    
    # 3. åŠå²›ç”µè§†å° (å…¨çƒå—æ–¹è§†è§’)
    "AL_JAZEERA": "https://www.aljazeera.com/xml/rss/all.xml"
}

# ---------------- HTTP SESSION ----------------
def make_session():
    s = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502], allowed_methods=["GET", "POST"])
    s.mount("https://", HTTPAdapter(max_retries=retries))
    return s

SESSION = make_session()

# ---------------- UTILS: TIME FILTER ----------------
def is_recent(entry, hours=24):
    """
    ç‰©ç†çº§æ—¶é—´è¿‡æ»¤ï¼šä¸¥æ ¼ä¸¢å¼ƒè¶…è¿‡ 24 å°æ—¶çš„æ—§é—»
    """
    # 1. Google News é€šå¸¸æœ‰ published_parsed
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        try:
            pub_time = datetime.fromtimestamp(mktime(entry.published_parsed))
            # å…è®¸ä¸€ç‚¹æ—¶åŒºè¯¯å·®ï¼Œè®¾å®šä¸º 25 å°æ—¶
            if datetime.now() - pub_time < timedelta(hours=25):
                return True
            else:
                return False # å¤ªæ—§äº†
        except:
            pass # è§£æå¤±è´¥å¾€ä¸‹èµ°
            
    # 2. å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œæ£€æŸ¥æ ‡é¢˜é‡Œæ˜¯å¦æœ‰ "Live", "Just now" ç­‰è¯ (å¯é€‰)
    # ä¸ºäº†ä¸¥æ ¼èµ·è§ï¼Œæ²¡æœ‰æ—¶é—´æˆ³çš„å¦‚æœæ˜¯ Google News æ¥æºï¼Œæœ€å¥½ä¸¢å¼ƒï¼Œé˜²æ­¢ 2008 å¹´æ—§é—»
    # ä½† Al Jazeera æœ‰æ—¶æ—¶é—´æˆ³æ ¼å¼ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬é»˜è®¤ï¼šå¦‚æœè§£æä¸åˆ°æ—¶é—´ï¼Œä¸”æ˜¯ç½®é¡¶æ–°é—»ï¼Œæš‚ä¸”æ”¾è¡Œï¼Œé  Prompt äºŒæ¬¡æ¸…æ´—
    return True 

# ---------------- GEMINI ENGINE ----------------
def get_api_url():
    url = f"{BASE_URL}/models?key={GEMINI_API_KEY}"
    try:
        r = SESSION.get(url, timeout=10)
        if r.status_code != 200: return None
        models = r.json().get("models", [])
        cands = [m["name"] for m in models if "generateContent" in m.get("supportedGenerationMethods", [])]
        priority = ["gemini-2.0-pro", "gemini-1.5-pro", "gemini-2.5", "gemini-2.0-flash"]
        chosen = next((m for p in priority for m in cands if p in m), cands[0] if cands else None)
        if chosen:
            log.info(f"âœ… AI Engine: {chosen}")
            return f"{BASE_URL}/{chosen}:generateContent"
    except: pass
    return None

def call_gemini(prompt, base_url, json_mode=False):
    url = f"{base_url}?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.2} 
    }
    if json_mode: payload["generationConfig"]["responseMimeType"] = "application/json"
    
    try:
        r = SESSION.post(url, headers=headers, json=payload, timeout=100)
        if r.status_code != 200:
            log.error(f"Gemini Error: {r.text}")
            return None
        return r.json()['candidates'][0]['content']['parts'][0]['text']
    except Exception as e:
        log.error(f"Gemini Net Error: {e}")
        return None

# ---------------- PIPELINE ----------------

def step1_scan_headlines():
    log.info("ğŸ“¡ [Step 1] Scanning Global & China Feeds (Strict 24H)...")
    combined_titles = []
    
    for category, url in RSS_POOLS.items():
        try:
            d = feedparser.parse(url)
            count = 0
            for e in d.entries:
                if is_recent(e, hours=24):
                    # ç»™æ ‡é¢˜åŠ ä¸Šå‰ç¼€ï¼Œæ–¹ä¾¿ AI è¯†åˆ«æ¥æº
                    clean_title = e.get("title", "").split(" - ")[0]
                    # å¦‚æœæ¥è‡ªä¸­å›½æºï¼ŒåŠ ä¸ªæ ‡è®°å¼ºæç¤º
                    prefix = "[CHINA NEWS]" if category == "CHINA_HOT" else "[GLOBAL]"
                    combined_titles.append(f"{prefix} {clean_title}")
                    count += 1
                if count >= 15: break # æ¯ä¸ªæºå–æœ€æ–°15æ¡
        except Exception as e:
            log.error(f"Feed error {category}: {e}")

    random.shuffle(combined_titles)
    # åªè¦å‰ 60 æ¡ï¼Œé˜²æ­¢ Token æº¢å‡º
    final_list = combined_titles[:60]
    log.info(f"   -> Found {len(final_list)} fresh headlines.")
    return final_list

def step2_select_topics(headlines, api_url):
    log.info("ğŸ§  [Step 2] AI Selecting 5 Events (Must Include China)...")
    
    # ğŸ”¥ Prompt å¼ºçº¦æŸï¼šå¿…é¡»åŒ…å«ä¸­å›½ï¼Œå¿…é¡»æ˜¯å…·ä½“äº‹ä»¶
    prompt = (
        f"Role: Chief Editor. Current Date: {datetime.now().strftime('%Y-%m-%d')}\n"
        "Task: Select Top 5 BREAKING NEWS EVENTS from the list.\n"
        "MANDATORY REQUIREMENTS:\n"
        "1. âœ… MUST include at least 1 event related to CHINA (look for [CHINA NEWS] tag).\n"
        "2. âœ… Select only CONCRETE EVENTS (e.g. 'SpaceX Launch', 'Earthquake in Japan').\n"
        "3. âŒ IGNORE general topics (e.g. 'Technology trends', 'Climate Change').\n"
        "4. âŒ IGNORE anything that looks like old news (2008 crisis, etc).\n"
        "Output: JSON array of search queries.\n"
        "Headlines Pool:\n" + "\n".join(headlines)
    )
    
    raw = call_gemini(prompt, api_url, json_mode=True)
    if not raw: return []
    try:
        clean = raw.replace("```json", "").replace("```", "").strip()
        topics = json.loads(clean)
        log.info(f"ğŸ”¹ Selected: {topics}")
        return topics
    except: return []

def fetch_topic_details(topic):
    # ğŸ”¥ æ ¸å¿ƒï¼šæœç´¢æ—¶åŠ  "when:1d" å¼ºåˆ¶ Google åªç»™ 24å°æ—¶å†…æ•°æ®
    # ğŸ”¥ æ ¸å¿ƒï¼šgl=GB ä½¿ç”¨è‹±å›½ç‰ˆï¼Œé¿å…ç¾å›½è§†è§’
    search_query = f"{topic} when:1d"
    url = f"https://news.google.com/rss/search?q={requests.utils.quote(search_query)}&hl=en-GB&gl=GB&ceid=GB:en"
    
    try:
        d = feedparser.parse(url)
        if not d.entries: return "" # æœä¸åˆ°ç›´æ¥ç©ºï¼Œè§¦å‘ç†”æ–­
        
        block = f"### EVENT: {topic}\n"
        valid_count = 0
        for e in d.entries:
            if is_recent(e, hours=24):
                summary = re.sub("<[^<]+?>", "", e.get("summary", ""))[:350]
                src = e.get("source", {}).get("title", "Unknown")
                pub = e.get("published", "")
                block += f"- [{pub}] {src}: {summary}\n"
                valid_count += 1
                if valid_count >= 3: break
        
        return block if valid_count > 0 else ""
    except: return ""

def step3_deep_research(topics):
    log.info(f"ğŸ•µï¸ [Step 3] Deep Researching {len(topics)} events...")
    results = []
    with ThreadPoolExecutor(max_workers=5) as ex:
        futures = [ex.submit(fetch_topic_details, t) for t in topics]
        for f in as_completed(futures):
            res = f.result()
            if res: results.append(res)
            
    if not results:
        log.error("âŒ No valid news found after strict filtering!")
        return None
    return "\n".join(results)

def step4_write_scripts(research_data, api_url):
    log.info("âœï¸ [Step 4] Writing Scripts (Anti-Hallucination)...")
    today = datetime.now().strftime("%Y-%m-%d")

    # 1. ç®€æŠ¥
    p_brief = (
        f"Role: Editor. Date: {today}.\n"
        f"Task: Write Telegram Markdown summary.\n"
        f"Rule: ONLY use facts from Data. MUST cover the China story.\n"
        f"Format:\nğŸ“… **æ—©å®‰ç®€æŠ¥ {today}**\n\nğŸ”¥ **ä»Šæ—¥äº”å¤§çƒ­ç‚¹**\n1. **[Headline]** - [Detail]\n...\n"
        f"Data:\n{research_data}"
    )
    text = call_gemini(p_brief, api_url)

    # 2. ä¸­æ–‡å¯¼è¯­ (å¤®è§†é£)
    p_cn = (
        f"Role: Anchor. Date: {today}. Style: CCTV News.\n"
        f"Task: Spoken Intro. Cover top stories including China.\n"
        f"Rule: No 'First/Second'. Be concise. NO hallucinations.\n"
        f"Start: 'è¿™é‡Œæ˜¯Fredlyæ—©é—´æ–°é—»ã€‚ä»Šå¤©æ˜¯{today}ã€‚'\n"
        f"Data:\n{research_data}"
    )
    cn = call_gemini(p_cn, api_url)

    # 3. è‹±æ–‡æ­£æ–‡ (BBCé£)
    p_en = (
        f"Role: Senior Correspondent. Task: {TARGET_MINUTES}-minute report.\n"
        f"Style: BBC/Al Jazeera. International perspective.\n"
        f"RULES:\n"
        f"1. CITE SOURCES (e.g. 'According to BBC...').\n"
        f"2. NO INTRO. Start with the most impactful story.\n"
        f"3. Ensure the China-related story is covered in depth.\n"
        f"Data:\n{research_data}"
    )
    en = call_gemini(p_en, api_url)
    return text, cn, en

# ---------------- RUNNER ----------------
def run_verification():
    log.info("ğŸ§ª STARTING VERIFICATION (Strict 24H + China Focus)")
    api_url = get_api_url()
    if not api_url: return

    # 1. Scan
    headlines = step1_scan_headlines()
    if not headlines: 
        log.error("âŒ No headlines found. Check network.")
        return

    # 2. Select
    topics = step2_select_topics(headlines, api_url)
    if not topics: return

    # 3. Research
    research = step3_deep_research(topics)
    if not research: return
    
    print(f"\nğŸ“ RESEARCH DATA SAMPLE:\n{research[:500]}...\n")

    # 4. Write
    text, cn, en = step4_write_scripts(research, api_url)
    
    print("\n" + "="*40 + "\nğŸ“¢ TELEGRAM BRIEF\n" + "="*40)
    print(text)
    print("\n" + "="*40 + "\nğŸ‡¨ğŸ‡³ CHINESE INTRO\n" + "="*40)
    print(cn)
    print("\n" + "="*40 + "\nğŸ‡¬ğŸ‡§ ENGLISH SCRIPT\n" + "="*40)
    print(en[:1500] + "...\n")
    
    log.info("âœ… Verification Complete.")

if __name__ == "__main__":
    # ç›´æ¥è¿è¡ŒéªŒè¯
    run_verification()
