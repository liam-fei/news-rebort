# =============================================
# Fredly News Bot - PRODUCTION EDITION
# ç‰¹æ€§ï¼šå…¨çƒè§†è§’ + å¼ºåˆ¶ä¸­å›½çƒ­ç‚¹ + ä¸¥æ ¼24Hæ—¶æ•ˆ + è‡ªåŠ¨å‘é€Telegram
# =============================================

import os
import sys
import time
import json
import tarfile
import asyncio
import shutil
import re
import subprocess
import logging
import random
from datetime import datetime, timedelta
from time import mktime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
import feedparser
import schedule
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from telegram.ext import Application
from telegram.request import HTTPXRequest

# ---------------- LOGGING ----------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S"
)
log = logging.getLogger("Fredly_Prod")

# ---------------- CONFIG ----------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

if not all([GEMINI_API_KEY, TELEGRAM_BOT_TOKEN, CHAT_ID]):
    log.error("âŒ Error: Missing Environment Variables (GEMINI_API_KEY, TELEGRAM_BOT_TOKEN, CHAT_ID)")
    sys.exit(1)

BASE_URL = "https://generativelanguage.googleapis.com/v1beta"
VOICE_CN = "zh-CN-XiaoxiaoNeural"
VOICE_EN = "en-US-AvaNeural"
TARGET_MINUTES = 13

OUTPUT_DIR = Path("./outputs")
BIN_DIR = Path("./bin")
OUTPUT_DIR.mkdir(exist_ok=True)
BIN_DIR.mkdir(exist_ok=True)

# ---------------- RSS SOURCES ----------------
# ç»„åˆæ‹³ï¼šè‹±å›½ç‰ˆGoogle(å…¨çƒè§†é‡) + ä¸­å›½ä¸“å±æœç´¢ + åŠå²›(å—æ–¹è§†è§’)
RSS_POOLS = {
    "GLOBAL": "https://news.google.com/rss?hl=en-GB&gl=GB&ceid=GB:en",
    "CHINA": "https://news.google.com/rss/search?q=China+when:1d&hl=en-GB&gl=GB&ceid=GB:en",
    "AL_JAZEERA": "https://www.aljazeera.com/xml/rss/all.xml"
}

# ---------------- HTTP SESSION ----------------
def make_session():
    s = requests.Session()
    # ç§»é™¤ 429 è‡ªåŠ¨é‡è¯•ï¼Œæ”¹ç”¨æ‰‹åŠ¨é•¿ç­‰å¾…
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504], allowed_methods=["GET", "POST"])
    s.mount("https://", HTTPAdapter(max_retries=retries))
    return s

SESSION = make_session()

# ---------------- UTILS ----------------
def is_recent(entry, hours=24):
    """ç‰©ç†è¿‡æ»¤ï¼šä¸¥æ ¼ä¸¢å¼ƒ 24 å°æ—¶å‰çš„æ—§é—»"""
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        try:
            pub_time = datetime.fromtimestamp(mktime(entry.published_parsed))
            # æ”¾å®½åˆ° 26 å°æ—¶ä»¥é˜²æ—¶åŒºè®¡ç®—è¯¯å·®
            if datetime.now() - pub_time < timedelta(hours=26):
                return True
            return False 
        except: pass
    # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ä¸”æ˜¯ Google æºï¼Œé€šå¸¸æ˜¯ç½®é¡¶æ–°é—»ï¼Œæš‚æ—¶æ”¾è¡Œ
    return True 

def ensure_ffmpeg():
    if shutil.which("ffmpeg"): return True
    ffmpeg_path = BIN_DIR / "ffmpeg"
    if ffmpeg_path.exists():
        os.environ["PATH"] += os.pathsep + str(BIN_DIR.resolve())
        return True
    log.info("ğŸ› ï¸ Installing FFmpeg...")
    try:
        url = "https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz"
        r = SESSION.get(url, stream=True, timeout=60)
        with open(BIN_DIR/"ffmpeg.tar.xz", "wb") as f: f.write(r.content)
        with tarfile.open(BIN_DIR/"ffmpeg.tar.xz") as tar:
            m = next(m for m in tar.getmembers() if m.name.endswith("/ffmpeg"))
            m.name = "ffmpeg"; tar.extract(m, BIN_DIR)
        (BIN_DIR/"ffmpeg").chmod(0o755)
        os.environ["PATH"] += os.pathsep + str(BIN_DIR.resolve())
        return True
    except: return False

# ---------------- GEMINI ENGINE ----------------
def get_api_url():
    url = f"{BASE_URL}/models?key={GEMINI_API_KEY}"
    try:
        r = SESSION.get(url, timeout=10)
        if r.status_code != 200: return None
        models = r.json().get("models", [])
        cands = [m["name"] for m in models if "generateContent" in m.get("supportedGenerationMethods", [])]
        
        # ä¼˜å…ˆä½¿ç”¨ Flash (é€Ÿåº¦å¿«ä¸”é…é¢è¾ƒå¤š)ï¼ŒPro ç”¨äºå…œåº•
        priority = ["gemini-1.5-flash", "gemini-2.5", "gemini-2.0-flash", "gemini-1.5-pro"]
        chosen = next((m for p in priority for m in cands if p in m), cands[0] if cands else None)
        
        if chosen:
            log.info(f"âœ… AI Engine: {chosen}")
            return f"{BASE_URL}/{chosen}:generateContent"
    except: pass
    return None

def call_gemini(prompt, base_url, json_mode=False):
    url = f"{base_url}?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.2} # ä½æ¸©ï¼Œä¸¥è°¨äº‹å®
    }
    if json_mode: payload["generationConfig"]["responseMimeType"] = "application/json"
    
    # æ‰‹åŠ¨é‡è¯•å¾ªç¯ï¼Œå¤„ç† 429 é™æµ
    for attempt in range(3):
        try:
            r = SESSION.post(url, headers=headers, json=payload, timeout=100)
            if r.status_code == 200:
                return r.json()['candidates'][0]['content']['parts'][0]['text']
            elif r.status_code == 429:
                wait = (attempt + 1) * 20 # é‡åˆ°é™æµç­‰å¾… 20s, 40s...
                log.warning(f"âš ï¸ Rate Limited (429). Sleeping {wait}s...")
                time.sleep(wait)
                continue
            else:
                log.error(f"Gemini API Error {r.status_code}: {r.text}")
                return None
        except Exception as e:
            log.error(f"Network Error: {e}")
            time.sleep(5)
    return None

# ---------------- PIPELINE ----------------

def step1_scan_headlines():
    log.info("ğŸ“¡ [Step 1] Scanning Global & China Feeds...")
    combined = []
    
    for cat, url in RSS_POOLS.items():
        try:
            d = feedparser.parse(url)
            count = 0
            for e in d.entries:
                if is_recent(e, hours=24):
                    title = e.get("title", "").split(" - ")[0]
                    # æ ‡è®°æ¥æºï¼Œæ–¹ä¾¿ Step 2 è¯†åˆ«ä¸­å›½æ–°é—»
                    prefix = "[CHINA]" if cat == "CHINA" else "[GLOBAL]"
                    combined.append(f"{prefix} {title}")
                    count += 1
                if count >= 15: break
        except Exception as e: log.error(f"Feed error {cat}: {e}")
    
    random.shuffle(combined)
    final = combined[:60]
    log.info(f"   -> Found {len(final)} fresh headlines.")
    return final

def step2_select_topics(headlines, api_url):
    log.info("ğŸ§  [Step 2] AI Selecting Top 5 Events (Strict Mode)...")
    today = datetime.now().strftime('%Y-%m-%d')
    prompt = (
        f"Role: Chief Editor. Date: {today}\n"
        "Task: Select Top 5 BREAKING NEWS EVENTS.\n"
        "RULES:\n"
        "1. âœ… MUST include at least 1 event related to CHINA (look for [CHINA] tag).\n"
        "2. âœ… Select ONLY specific, concrete events from the LAST 24 HOURS.\n"
        "3. âŒ REJECT broad topics (e.g. 'Technology', 'Economy') or old news.\n"
        "Output: JSON array of search queries.\n"
        "Headlines:\n" + "\n".join(headlines)
    )
    raw = call_gemini(prompt, api_url, json_mode=True)
    if not raw: return []
    try:
        return json.loads(raw.replace("```json", "").replace("```", "").strip())
    except: return []

def fetch_details(topic):
    # å¼ºåˆ¶æœç´¢ 24h å†… + è‹±å›½ç‰ˆ(å…¨çƒè§†è§’)
    query = f"{topic} when:1d"
    url = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=en-GB&gl=GB&ceid=GB:en"
    try:
        time.sleep(1) # ç¤¼è²Œå»¶è¿Ÿï¼Œé˜²å°
        d = feedparser.parse(url)
        if not d.entries: return ""
        
        block = f"### EVENT: {topic}\n"
        valid = 0
        for e in d.entries:
            if is_recent(e, hours=24):
                summary = re.sub("<[^<]+?>", "", e.get("summary", ""))[:350]
                src = e.get("source", {}).get("title", "Unknown")
                block += f"- {src}: {summary}\n"
                valid += 1
                if valid >= 3: break
        return block if valid > 0 else ""
    except: return ""

def step3_deep_research(topics):
    log.info(f"ğŸ•µï¸ [Step 3] Researching {len(topics)} events...")
    results = []
    # é™åˆ¶å¹¶å‘ä¸º3ï¼Œé¿å…è§¦å‘ 429
    with ThreadPoolExecutor(max_workers=3) as ex:
        futures = [ex.submit(fetch_details, t) for t in topics]
        for f in as_completed(futures):
            res = f.result()
            if res: results.append(res)
    
    if not results:
        log.error("âŒ No valid recent news found (Circuit Breaker Triggered).")
        return None
    return "\n".join(results)

def step4_write_scripts(data, api_url):
    log.info("âœï¸ [Step 4] Writing Scripts...")
    today = datetime.now().strftime("%Y-%m-%d")

    # 1. Telegram Brief
    p_brief = (
        f"Role: Editor. Date: {today}.\n"
        f"Task: Write Telegram Markdown summary.\n"
        f"Rule: STRICTLY based on Data. MUST cover the China story.\n"
        f"Format:\nğŸ“… **æ—©å®‰ç®€æŠ¥ {today}**\n\nğŸ”¥ **ä»Šæ—¥äº”å¤§çƒ­ç‚¹**\n1. **[Headline]** - [Detail]\n...\n"
        f"Data:\n{data}"
    )
    text = call_gemini(p_brief, api_url)

    # 2. Chinese Intro
    p_cn = (
        f"Role: Anchor. Date: {today}. Style: CCTV News.\n"
        f"Task: Spoken Intro. Cover top stories + China story.\n"
        f"Rule: No 'First/Second'. Be concise. NO hallucinations.\n"
        f"Start: 'è¿™é‡Œæ˜¯ä¸“å±GDçš„æ—©é—´æ–°é—»ã€‚ä»Šå¤©æ˜¯{today}ã€‚'\n"
        f"Data:\n{data}"
    )
    cn = call_gemini(p_cn, api_url)

    # 3. English Deep Dive
    p_en = (
        f"Role: Senior Correspondent. Task: {TARGET_MINUTES}-minute report.\n"
        f"Style: BBC/Al Jazeera. International perspective.\n"
        f"Rules: CITE SOURCES. NO INTRO (Start with story). Cover China story in depth.\n"
        f"Data:\n{data}"
    )
    en = call_gemini(p_en, api_url)
    return text, cn, en

# ---------------- PRODUCTION ----------------
async def send_to_user(text, cn, en):
    if not ensure_ffmpeg(): return
    log.info("ğŸ™ï¸ Processing Audio...")
    
    f_cn = OUTPUT_DIR / "cn.mp3"
    f_en = OUTPUT_DIR / "en.mp3"
    f_final = OUTPUT_DIR / "final.mp3"
    
    await edge_tts.Communicate(cn, VOICE_CN).save(f_cn)
    await edge_tts.Communicate(en, VOICE_EN).save(f_en)
    
    # æ··éŸ³: æ‹¼æ¥ + éŸ³é‡1.3å€
    subprocess.run(
        ["ffmpeg", "-y", "-i", str(f_cn), "-i", str(f_en), 
         "-filter_complex", "[0:a][1:a]concat=n=2:v=0:a=1[a];[a]volume=1.3[out]", 
         "-map", "[out]", str(f_final)],
        check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
    )
    
    log.info("ğŸ“¤ Sending to Telegram...")
    t_req = HTTPXRequest(read_timeout=300, write_timeout=300)
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).request(t_req).build()
    
    async with app:
        await app.initialize()
        # å‘é€æ–‡å­—ç®€æŠ¥
        if text:
            safe = text.replace("#", "")
            try: await app.bot.send_message(CHAT_ID, safe, parse_mode="Markdown")
            except: await app.bot.send_message(CHAT_ID, safe)
        # å‘é€éŸ³é¢‘
        if f_final.exists():
            d = datetime.now().strftime("%Y-%m-%d")
            with open(f_final, "rb") as f:
                await app.bot.send_audio(CHAT_ID, f, title=f"News {d}", caption=f"ğŸ§ Briefing {d}")
            f_final.unlink()
    
    f_cn.unlink(); f_en.unlink()
    log.info("âœ… Job Complete!")

def job():
    log.info(">>> Job Started")
    try:
        api = get_api_url()
        if not api: return
        
        headlines = step1_scan_headlines()
        if not headlines: return
        
        topics = step2_select_topics(headlines, api)
        if not topics: return
        
        data = step3_deep_research(topics)
        if not data: return
        
        txt, c, e = step4_write_scripts(data, api)
        if c and e:
            asyncio.run(send_to_user(txt, c, e))
            
    except Exception as e:
        log.error(f"Critical Job Error: {e}")
    log.info("<<< Job Finished")

# ---------------- MAIN ----------------
if __name__ == "__main__":
    from keep_alive import keep_alive
    keep_alive() # å¯åŠ¨ Web Server é˜²ä¼‘çœ 
    
    log.info("ğŸš€ Fredly Bot (Production) Ready")
    
    # å®šæ—¶ä»»åŠ¡: æ¯å¤© UTC 03:00 (è¿ªæ‹œ 07:00)
    schedule.every().day.at("03:00").do(job)

    # å¦‚éœ€ç«‹å³æµ‹è¯•ï¼Œåœ¨ Render ç¯å¢ƒå˜é‡è®¾ç½® RUN_NOW=true
    if os.getenv("RUN_NOW", "false").lower() == "true":
        log.info("âš¡ Manual Trigger Detected")
        job()

    while True:
        schedule.run_pending()
        time.sleep(60)
